---
layout: post
title:  "CS231n | 5강 - Convolutional Neural Networks"
date:   2021-08-04
author: danahkim
tags: CS231n
categories: Deep-Learning
---

[CS231n] Lecture-5-Convolutional-Neural-Networks  
[5강 Video 바로가기](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5)

- Contents
  - History
  - Convolution and pooling
  - ConvNets outside vision

------



## History

Convolutional Neural Network에 들어가기 앞서 Computer Vision에 대한 히스토리를 소개한다. 이것은 1강 Orientation에 Fei-Fei Li 교수님이 한 강의와 대다수 동일하므로 생략하도록 한다. 1강 강의 정리 참고



## Convolutional Neural Networks

### (First without the brain stuff)

일단 Convolutional Neural Network에 대해서 수식적으로 크게 머리를 쓰지 않고 컨셉을 이해하고 시작하도록 한다.

![image](https://user-images.githubusercontent.com/62828866/127259278-d420209e-941a-4d1e-bc15-820cd0d8d2cc.png)

지난 시간에 우리는 Fully Connected Layer에 대해 배웠다. 예를 들어 32x32x3 크기의 이미지가 있다면 이것을 **3072길이의 1차원 벡터로 길게 늘이고**, 가중치 행렬인 W와 내적하여 각 class에 대한 score를 구한다.

![image](https://user-images.githubusercontent.com/62828866/127259739-68395762-aaac-44b7-b87d-436fcb31f50f.png)

Convolution Layer는 1개의 긴 벡터로 만들지 않고 **이미지 모양 그대로 학습하여** 공간 구조를 보존한다. 이것이 가장 큰 차이점이다.

![image](https://user-images.githubusercontent.com/62828866/127771894-26b53842-3008-4a43-b2f1-c3c40ef98857.png)

이미지가 있으면 동일한 depth의 **필터**를 이용해서 이미지를 *공간적으로* 내적한다. (어떻게 계산하고 적용되는지 그 디테일에 대해서는 뒤에서 다룰 것이다.)

![image](https://user-images.githubusercontent.com/62828866/127772058-5cea0c24-61aa-4c59-912a-d10e667613ab.png)
그런데 element-wise로 곱하는 것은 결국 필터(w)와 이미지(x)를 쭉 펼치고 그것을 내적하는 것과 같다. 그래서 **w’x+b**라는 우리가 배운 간단한 수식으로 표현할 수도 있다.

![image-20210801222258723](C:\Users\Danah\AppData\Roaming\Typora\typora-user-images\image-20210801222258723.png)
모든 공간에서 이 필터를 곱하는 계산을 해서 1개의 필터로 1개의 **activation map**을 만든다.

![image](https://user-images.githubusercontent.com/62828866/128187518-b7585a69-276e-490a-acb5-20195d11b619.png)



그리고 또 다른 필터를 추가해서 수행할 수 있는데, 6개의 필터를 사용하면 6개의 activation map을 얻을 수 있다.

![image](https://user-images.githubusercontent.com/62828866/127773726-28a18e9e-98cf-44be-aa43-93cc6e2a2bd1.png)
쌓아진 activation map에 또 필터를 곱해서 계속 레이어를 쌓을 수 있다.

![image](https://user-images.githubusercontent.com/62828866/127773932-00c94725-fc78-409e-8be1-4ea160534d88.png)
이렇게 계속 레이어를 스택하면 어떻게 될까?
위 예시를 보자. 하나의 그리드가 하나의 뉴런이라고 생각하면 된다. 그리고 그 뉴런이 가장 잘 반응하는 이미지를 나타냈다고 보면 된다.
처음에는 edge를 찾는 저차원수준이고, 중간에는 좀 더 복잡한 모양인데 코너 같은 것을 찾을 수 있다. 그리고 점점 반복할 수록 고차원의 형상을 나타내게 된다.
레이어를 계층적으로 스택하는 것을 이렇듯 고차원을 표현할 수 있게 된다는 것이다.
그러므로 필터의 크기나 모양, stride, 필터의 개수 같은 것을 정하는 것은 분석자의 중요한 디자인이다.

![image](https://user-images.githubusercontent.com/62828866/127774144-726a3006-4b1e-4905-b1bb-2078710a74d8.png)
위처럼 Convolution, RELU, Pooling등의 연속된 레이어를 지나면서 비선형으로 바뀌고 마지막에는 fully connected layer로 리턴하면서 이미지인지 score를 보여준다

이제 어떻게 공간 차원에 필터가 작용하는지 예시를 보자.

![image](https://user-images.githubusercontent.com/62828866/127774458-ccd5af41-b6e2-403a-8500-fe3641a27125.png)

![image](https://user-images.githubusercontent.com/62828866/127774481-1d2a1809-865a-4f6c-942a-92ce7aa6a0b6.png)

위는 3x3 필터가 stride가 1일때 어떻게 계산되는지 보여주는 예시이다. slide는 공간을 이동하는 칸 수를 의미한다. 공간을 1칸씩 slide하면서 element-wise로 값을 곱한다.

![image](https://user-images.githubusercontent.com/62828866/127774778-7462a503-20ac-46d5-be08-7094667b6b5e.png)

7x7의 이미지에서 3x3의 필터를 적용한다면 stride=1일 때 7-3+1=5로 5x5의 크기의 activation map을 갖는다.
stride=2로 하면 2칸씩 좌우로 움직이는데 따라서 (7-3)/2+1=3으로 3x3의 크기를 가지게 된다.
stride=3일때는 2.3이 되는데.. 이 때는 **패딩**을 이용한다!

![image](https://user-images.githubusercontent.com/62828866/127774826-3c498e53-5500-40d3-8c4b-4cf32fa5885a.png)

패딩 1을 한다면 이미지 주변으로 1칸의 값을 넣는다. 위의 예시에는 패딩 값이 0이지만 0이 아니라 그 주변의 값을 mirroring해서 쓸 수도 있다. 패딩을 하면 stride=1일때 9-3+1= 7이 된다.

![image](https://user-images.githubusercontent.com/62828866/127774873-cade6f2b-b3b7-4f6a-964f-5a89e2474ce2.png)
이렇듯 필터를 지나면 이미지의 크기가 작아지기 때문에, 패딩은 이미지 원래의 사이즈를 공간적으로 잃지 않고 보존하게 해주는 역할을 한다. 또한 패딩을 통해 테두리 부분의 이미지의 정보를 잃지 않게 해준다.
통상적으로 필터 사이즈로 3x3, 5x5, 7x7을 많이 쓰는데, 이 때 적당한 크기의 패딩을 사용하여 사이즈가 많이 줄지 않게 만든다.

![image](https://user-images.githubusercontent.com/62828866/127774966-751c760e-5fa5-4c10-8fcb-8f7598464309.png)
연속적인 레이어를 반복하면 이미지의 크기가 빠르게 줄어들고 이것은 엣지의 인포메이션을 잃는 것이기 때문에 좋지 않다.

![image](https://user-images.githubusercontent.com/62828866/127774988-7ce92de1-bc3d-44bd-b5e2-13071df738d1.png)
이때 패딩을 사용한다면 사이즈를 잃지 않은 activation map을 구할 수 있다.

32x32x3의 이미지에 5x5x3의 필터, stride=1을 이용할 때, 원래는 이미지가 28x28로 줄어든다. 그러나 pad=2의 패딩을 이용하면 이미지의 크기 32를 보존할 수 있다!

![image](https://user-images.githubusercontent.com/62828866/127775543-a37abac8-9c81-47f0-91af-0c8ec02cb456.png)
parameter 또한 w에 해당하는 필터의 paramter값으로 구할 수 있는데 여기서 중요한것은 bias term을 하나 꼭 더해줘야한다. 

![image](https://user-images.githubusercontent.com/62828866/127772859-34ef8d9b-6f5c-47ac-bf57-eada8321bdfb.png)

7x7x3의 이미지에 3x3x3 필터 2개가 구체적으로 어떻게 계산이 되는지 나타낸 그림이다. [ConvNet notes](https://cs231n.github.io/convolutional-networks/)를 참고하면 자세한 설명과 예시를 볼 수 있다.

![image](https://user-images.githubusercontent.com/62828866/127775042-bc3ff652-7b98-4d24-94fa-a2da5ab8a6bd.png)

![image](https://user-images.githubusercontent.com/62828866/127776011-ba4e812e-2c79-4a3e-8a17-42b0785c9a5e.png)

PyTorch 프레임워크로 CNN을 구현할 수 있는데 안에 있는, 디자인은 본인이 설정할 수 있다. 

![image](https://user-images.githubusercontent.com/62828866/127775075-304dc533-faf8-489a-b1f9-d40b10b123a7.png)
Stride의 크기는 결국 activation map을 작게해서 다운사이즈 시키는데 parameter가 줄어들고 오버피팅을 막는다. 이와 비슷하게 pooling layer은 이미지를 downsampling해서 공간적으로 줄인다.

![image](https://user-images.githubusercontent.com/62828866/127775089-0ff6345b-d21c-4ac8-8e82-15d0bc585272.png)Max-pooling을 가장 많이 쓰는데 그 공간에서 가장 큰 값만 가져오는 것이다. 그 공간을 가장 잘 나타내는 값 1개로 줄이는 거라고 직관적으로 이해하면 된다. 

![image](https://user-images.githubusercontent.com/62828866/127775104-9848263a-0fd9-4cc3-8daf-461878da90a0.png)
풀링 레이어로 2x2, 3x3을 가장 많이 쓴다.

![image](https://user-images.githubusercontent.com/62828866/127775120-bfe98d6f-f8d6-4691-a617-cbf379dadb0e.png)
정리하면 CNN은 Convolution layer와 Pooling layer, Full-connected layer를 쌓은 구조이다.

작은 필터로 깊게 쌓는 구조와 Pooling layer와 Full-connected layer 없이 Convolution layer로만 쌓는 것이 최근 트렌드이다. 예를 들어, Conv, Relu 후에 pooling을 하는 레이어를 아주 여러 번 반복하고, 마지막에 Full-connected layer를 생략하거나 2번 정도로 한 후에 softmax를 거쳐 score가 나오는 아키텍쳐가 전형적이다.

그러나 최근에는 ResNet이나 GoogLeNet은 이러한 패러다임에 도전하여 좋은 성능을 냈다! 

(위는 2017년 기준이며 현재는 이보다 더 좋은 아키텍쳐가 더 많이 공개되었다. 주요 CNN 아키텍쳐를 설명해놓은 [블로그 글](https://hoya012.github.io/blog/deeplearning-classification-guidebook-4/)을 참고하면 좋을 것 같다.)
